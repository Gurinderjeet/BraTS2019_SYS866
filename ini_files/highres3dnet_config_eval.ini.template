############################ input configuration sections
[t1]
path_to_search =
filename_contains = t1
filename_not_contains = t1ce
spatial_window_size = (19, 144, 144)
axcodes=(L,P,S)
interp_order = 3

[t2]
path_to_search =
filename_contains = t2
filename_not_contains =
spatial_window_size = (19, 144, 144)
axcodes=(L,P,S)
interp_order = 3

[t1ce]
path_to_search =
filename_contains = t1ce
filename_not_contains =
spatial_window_size = (19, 144, 144)
axcodes=(L,P,S)
interp_order = 3

[flair]
path_to_search =
filename_contains = flair
filename_not_contains =
spatial_window_size = (19, 144, 144)
axcodes=(L,P,S)
interp_order = 3

[label]
path_to_search =
filename_contains = seg
filename_not_contains =
spatial_window_size = (11, 144, 144)
axcodes=(L,P,S)
interp_order = 0

[TRAINING]
optimiser = adam
sample_per_volume = 24
lr = 1e-3
loss_type = Dice
starting_iter = 0
save_every_n = 5000
max_iter = 30000
max_checkpoints = 20
exclude_fraction_for_validation = 0.2
validation_every_n = 48
tensorboard_every_n = 1

[SYSTEM]
cuda_devices = ""
model_dir = models/highres3dnet_brain_parcellation

[NETWORK]
name = highres3dnet
batch_size = 1
activation_function = relu
volume_padding_size = 10

whitening = True
normalisation = True
normalise_foreground_only=True
foreground_type = mean_plus
histogram_ref_file = databrain_std_hist_models_otsu.txt
cutoff = (0.001, 0.999)


[INFERENCE]
border = (4,0,0)
save_seg_dir = ./parcellation_output
output_interp_order = 3
spatial_window_size = (120, 144, 144)
inference_iter = 15000


[SEGMENTATION]
image = flair,t1,t1ce,t2
label = label
output_prob = True
num_classes = 4
label_normalisation = True